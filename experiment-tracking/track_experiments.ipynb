{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4ee3ba-bb4d-4982-afbf-dd9f0ebda699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168a4bf5-ed00-4c47-a4f2-ed5bb69447e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/mlops_temperature_prediction-M3ZLPW1f\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipenv --venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939b5203-d012-43e0-b1e8-fcc9ba662b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85e0052-4e7b-4a9c-a432-bd19e1d61ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1fdace-e31d-4c5c-8836-dabb02cd9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/london_weather.csv\"\n",
    "df = pd.read_csv(input_file, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1385cc58-33bd-439b-bcfd-d3215b6bf88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df[\"date\"],format='%Y%m%d')\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df[\"date\"].dt.month.map(\"{:02}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81eb2b55-46df-4186-8017-152d8ad4d9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>global_radiation</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>101900.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979-01-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102530.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-01-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102050.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1979-01-04</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100840.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979-01-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  cloud_cover  sunshine  global_radiation  max_temp  mean_temp  \\\n",
       "0 1979-01-01          2.0       7.0              52.0       2.3       -4.1   \n",
       "1 1979-01-02          6.0       1.7              27.0       1.6       -2.6   \n",
       "2 1979-01-03          5.0       0.0              13.0       1.3       -2.8   \n",
       "3 1979-01-04          8.0       0.0              13.0      -0.3       -2.6   \n",
       "4 1979-01-05          6.0       2.0              29.0       5.6       -0.8   \n",
       "\n",
       "   min_temp  precipitation  pressure  snow_depth  year month  \n",
       "0      -7.5            0.4  101900.0         9.0  1979    01  \n",
       "1      -7.5            0.0  102530.0         8.0  1979    01  \n",
       "2      -7.2            0.0  102050.0         4.0  1979    01  \n",
       "3      -6.5            0.0  100840.0         2.0  1979    01  \n",
       "4      -1.4            0.0  102250.0         1.0  1979    01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50adb93a-e227-45ef-ae70-8a7073b9af5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_all_features = df.drop([\"mean_temp\", \"date\"], axis=1).columns.to_list()\n",
    "numeric_features =  ['max_temp', 'min_temp', 'mean_temp', 'global_radiation', 'sunshine', 'cloud_cover', 'snow_depth', 'precipitation', 'pressure']\n",
    "weather_features = ['month', 'max_temp', 'min_temp', 'global_radiation', 'sunshine', 'cloud_cover', 'snow_depth']\n",
    "# weather_features = ['month', 'cloud_cover', 'sunshine', 'precipitation', 'pressure', 'global_radiation']\n",
    "weather_target = \"mean_temp\"\n",
    "df_weather = df.copy()\n",
    "# Fill the records with \"null\" mean_temp with the mean value\n",
    "# df_weather['mean_temp'] = df_weather.fillna(df_weather['mean_temp'].mean())['mean_temp']\n",
    "# df_weather[weather_features].fillna(df_weather[weather_features].mean(), inplace=True)\n",
    "[df_weather[col].fillna(df_weather[col].mean(), inplace=True) for col in numeric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b9703c5-18d3-4c5b-b0b6-56cab81805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                0\n",
      "cloud_cover         0\n",
      "sunshine            0\n",
      "global_radiation    0\n",
      "max_temp            0\n",
      "mean_temp           0\n",
      "min_temp            0\n",
      "precipitation       0\n",
      "pressure            0\n",
      "snow_depth          0\n",
      "year                0\n",
      "month               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_weather.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25699fb7-bc0c-41ff-ae83-80b93121a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  month  max_temp  min_temp  global_radiation  sunshine  cloud_cover  \\\n",
      "0    01       2.3      -7.5              52.0       7.0          2.0   \n",
      "1    01       1.6      -7.5              27.0       1.7          6.0   \n",
      "\n",
      "   snow_depth  \n",
      "0         9.0  \n",
      "1         8.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "The selected features are :  Index(['month', 'max_temp', 'min_temp', 'global_radiation', 'sunshine',\n",
      "       'cloud_cover', 'snow_depth'],\n",
      "      dtype='object')\n",
      "X_train :        month  max_temp  min_temp  global_radiation  sunshine  cloud_cover  \\\n",
      "256      09      17.4       4.7             157.0       7.1          4.0   \n",
      "12926    05      16.2      11.2             177.0       3.9          6.0   \n",
      "\n",
      "       snow_depth  \n",
      "256           0.0  \n",
      "12926         0.0  \n",
      "type(X_train) :  <class 'pandas.core.frame.DataFrame'>\n",
      "Original train DF :  [{'month': '09', 'max_temp': 17.4, 'min_temp': 4.7, 'global_radiation': 157.0, 'sunshine': 7.1, 'cloud_cover': 4.0, 'snow_depth': 0.0}, {'month': '05', 'max_temp': 16.2, 'min_temp': 11.2, 'global_radiation': 177.0, 'sunshine': 3.9, 'cloud_cover': 6.0, 'snow_depth': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "# Subset feature and target sets\n",
    "# X = df_weather[weather_all_features]    \n",
    "X = df_weather[weather_features]  \n",
    "y = df_weather[weather_target]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(X[0:2])\n",
    "print(type(X))\n",
    "print(\"The selected features are : \", X_train.columns)\n",
    "feature_index = X_train.columns\n",
    "print(\"X_train : \", X_train[0:2])\n",
    "print(\"type(X_train) : \", type(X_train))\n",
    "print(\"Original train DF : \", X_train[0:2].to_dict(orient='records'))\n",
    "    \n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "# Transform on the test data\n",
    "X_test  = dv.transform(X_test.to_dict(orient='records'))\n",
    "    \n",
    "# Scale the data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "# Fit on the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Transform on the test data\n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce176c4c-435f-405a-b24e-1e1bf342d660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9261    16.0\n",
       "5376    14.6\n",
       "Name: mean_temp, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "817bc2e9-4f72-445c-aaa3-4b8dd61931f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"models\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1619c04-4e1c-4bcb-b316-17399b12f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805220cb-5176-4155-9e4b-2ca7f3c087f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_reg_params = {\n",
    "#     'learning_rate':    hp.uniform('learning_rate',0.1,1),\n",
    "#     'max_depth':        hp.choice('max_depth',        np.arange(2, 100, 1, dtype=int)),\n",
    "#     'min_child_weight': hp.choice('min_child_weight', np.arange(1, 50, 1, dtype=int)),\n",
    "#     'colsample_bytree': hp.uniform('colsample_bytree',0.4,1),\n",
    "#     'subsample':        hp.uniform('subsample', 0.6, 1),\n",
    "#     'num_leaves':       hp.choice('num_leaves',       np.arange(1, 200, 1, dtype=int)),\n",
    "#     'min_split_gain':   hp.uniform('min_split_gain', 0, 1),\n",
    "#     'reg_alpha':        hp.uniform('reg_alpha',0,1),\n",
    "#     'reg_lambda':       hp.uniform('reg_lambda',0,1),\n",
    "#     'n_estimators':     5\n",
    "# }\n",
    "\n",
    "#     # params = {\n",
    "#     #     \"objective\": \"regression\",\n",
    "#     #     \"metric\": \"rmse\",\n",
    "#     #     \"n_estimators\": 1000,\n",
    "#     #     \"verbosity\": -1,\n",
    "#     #     \"bagging_freq\": 1,\n",
    "#     #     \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "#     #     \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "#     #     \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "#     #     \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "#     #     \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "#     # }\n",
    "\n",
    "\n",
    "# def objective(params):\n",
    "#   lgbm = lgb.LGBMRegressor(n_jobs=-1,early_stopping_rounds=None,**params)\n",
    "#   score = cross_val_score(lgbm, X_train, y_train, cv=2,scoring='neg_mean_squared_error',n_jobs=-1).mean()\n",
    "#   return score\n",
    "\n",
    "# trials = Trials()\n",
    "# result = fmin(\n",
    "#     fn=objective,           # objective function\n",
    "#     space=lgb_reg_params,   # parameter space\n",
    "#     algo=tpe.suggest,       # surrogate algorithm\n",
    "#     max_evals=50,           # no. of evaluations\n",
    "#     trials=trials           # trials object that keeps track of the sample results (optional)\n",
    "# )\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "056d1f18-2e61-4aaa-b901-85ff325ff639",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgbm_valid = lgb.Dataset(X_test, label=y_test, reference=lgbm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e39ec4d-dc01-4e63-913b-31d38fb82c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x7f1c2418fb50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e0d2d6-a16b-4b28-aab2-b577676097d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/18 18:43:31 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/08/18 18:43:32 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2024/08/18 18:43:41 INFO mlflow.tracking.fluent: Experiment with name 'compare-models' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/ubuntu/mlops_temperature_prediction/experiment-tracking/mlruns/1', creation_time=1723986821985, experiment_id='1', last_update_time=1723986821985, lifecycle_stage='active', name='compare-models', tags={}>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"compare-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c31a31b3-d128-45b4-9735-9621ccefe5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933\n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 11.487968\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"hema\")\n",
    "\n",
    "    mlflow.log_param(\"train-data-path\", input_file)\n",
    "    mlflow.log_param(\"test-data-path\",input_file)\n",
    "\n",
    "\n",
    "    # Liner Regression\n",
    "    lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred_lin_reg = lin_reg.predict(X_test)\n",
    "    lin_reg_rmse = mean_squared_error(y_test, y_pred_lin_reg, squared=False)\n",
    "    mlflow.log_metric(\"rmse_lr\", lin_reg_rmse)\n",
    "    # mlflow.sklearn.log_model(lin_reg, \"lin_reg\")\n",
    "    # with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "    #     pickle.dump((dv, lin_reg), f_out)\n",
    "    # mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_mlflow\")\n",
    "\n",
    "    # XG Boost Regressor\n",
    "    xgb_model = xgb.XGBRegressor(objective ='reg:squarederror', random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    pred_labels_xgb = xgb_model.predict(X_test)\n",
    "    xgb_rmse = mean_squared_error(y_test, pred_labels_xgb, squared=False)\n",
    "    mlflow.log_metric(\"rmse_xgb\", xgb_rmse)\n",
    "    # mlflow.xgboost.log_model(xgb_model, \"xgb_reg\")\n",
    "    # with open('models/xgb_reg.bin', 'wb') as f_out:\n",
    "    #     pickle.dump((dv, xgb_model), f_out)\n",
    "    # mlflow.log_artifact(local_path=\"models/xgb_reg.bin\", artifact_path=\"models_mlflow\")\n",
    "\n",
    "    # Gradient Boost Regressor\n",
    "    gbm_reg = GradientBoostingRegressor(random_state=42)\n",
    "    gbm_reg.fit(X_train, y_train)\n",
    "    y_pred_gb_reg = gbm_reg.predict(X_test)\n",
    "    gbm_reg_rmse = mean_squared_error(y_test, y_pred_gb_reg, squared=False)\n",
    "    mlflow.log_metric(\"rmse_gbm\", gbm_reg_rmse)\n",
    "    # mlflow.sklearn.log_model(gbm_reg, \"gbm_reg\")\n",
    "    # with open('models/gbm_reg.bin', 'wb') as f_out:\n",
    "    #     pickle.dump((dv, gbm_reg), f_out)\n",
    "    # mlflow.log_artifact(local_path=\"models/gbm_reg.bin\", artifact_path=\"models_mlflow\")\n",
    "\n",
    "    # Light Gradient Boost Regressor\n",
    "    lgbm_reg =  lgb.LGBMRegressor(random_state=42)\n",
    "    lgbm_reg.fit(X_train, y_train)\n",
    "    y_pred_lgb_reg = lgbm_reg.predict(X_test)\n",
    "    lgbm_reg_rmse = mean_squared_error(y_test, y_pred_lgb_reg, squared=False)\n",
    "    mlflow.log_metric(\"rmse_lgbm\", lgbm_reg_rmse)\n",
    "    # mlflow.sklearn.log_model(lgbm_reg, \"lgbm_reg\")\n",
    "    # with open('models/lgbm_reg.bin', 'wb') as f_out:\n",
    "    #     pickle.dump((dv, lgbm_reg), f_out)\n",
    "    # mlflow.log_artifact(local_path=\"models/lgbm_reg.bin\", artifact_path=\"models_mlflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "457bea88-f5fa-4afc-951b-dd4e94cfb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    mlflow.set_experiment(\"lgbm-best-model\")\n",
    "    with mlflow.start_run():\n",
    " \n",
    "        mlflow.set_tag(\"developer\", \"hema\")\n",
    "\n",
    "        mlflow.log_param(\"train-data-path\", input_file)\n",
    "        mlflow.log_param(\"test-data-path\",input_file)\n",
    "        mlflow.log_param(\"model\", \"lgbm\")\n",
    "    \n",
    "        lgbm = lgb.LGBMRegressor(n_jobs=-1,**params, metric='rmse')\n",
    "\n",
    "        lgbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "                 callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50)]\n",
    "                )\n",
    "        y_pred_lgbm_reg = lgbm.predict(X_test)\n",
    "        lgbm_rmse = mean_squared_error(y_test, y_pred_lgbm_reg, squared=False)\n",
    "        mlflow.log_metric(\"rmse_lgbm\", lgbm_rmse)\n",
    "        # mlflow.sklearn.log_model(lgbm, \"lgbm_reg\")\n",
    "        # with open('models/preprocessor.b', 'wb') as f_out:\n",
    "        #     pickle.dump((dv, lgbm), f_out)\n",
    "        # mlflow.log_artifact(local_path=\"models/preprocessor.b\", artifact_path=\"models_mlflow\")\n",
    "\n",
    "\n",
    "        return {'loss': lgbm_rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7071eb1d-d849-43e7-9a2e-567e3d64172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/18 18:54:20 INFO mlflow.tracking.fluent: Experiment with name 'lgbm-best-model' does not exist. Creating a new experiment.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[17]\tvalid_0's rmse: 0.96336\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[24]\tvalid_0's rmse: 0.931983\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[26]\tvalid_0's rmse: 0.938434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000625 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[33]\tvalid_0's rmse: 0.900554\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[99]\tvalid_0's rmse: 0.882528\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[132]\tvalid_0's rmse: 0.882813\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[49]\tvalid_0's rmse: 0.901266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000640 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[29]\tvalid_0's rmse: 0.925298\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000676 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[65]\tvalid_0's rmse: 0.888794\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[51]\tvalid_0's rmse: 0.901757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022731 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[71]\tvalid_0's rmse: 0.885581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[75]\tvalid_0's rmse: 0.886464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[12]\tvalid_0's rmse: 0.964885\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[78]\tvalid_0's rmse: 0.884838\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[29]\tvalid_0's rmse: 0.928812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000612 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[106]\tvalid_0's rmse: 0.88554\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[27]\tvalid_0's rmse: 0.9235\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000568 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[75]\tvalid_0's rmse: 0.889083\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[27]\tvalid_0's rmse: 0.910284\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[28]\tvalid_0's rmse: 0.924254\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004991 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[126]\tvalid_0's rmse: 0.883186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[140]\tvalid_0's rmse: 0.883894\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[139]\tvalid_0's rmse: 0.882697\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008810 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[115]\tvalid_0's rmse: 0.884755\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[52]\tvalid_0's rmse: 0.888958\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000533 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Did not meet early stopping. Best iteration is:                                                                         \n",
      "[111]\tvalid_0's rmse: 0.885004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[119]\tvalid_0's rmse: 0.885819\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[147]\tvalid_0's rmse: 0.882496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010136 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Did not meet early stopping. Best iteration is:                                                                         \n",
      "[109]\tvalid_0's rmse: 0.883855\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[50]\tvalid_0's rmse: 0.896281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000782 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[86]\tvalid_0's rmse: 0.88781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[179]\tvalid_0's rmse: 0.881216\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[151]\tvalid_0's rmse: 0.8833\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019395 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[116]\tvalid_0's rmse: 0.884783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[20]\tvalid_0's rmse: 0.994239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[137]\tvalid_0's rmse: 0.883379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[152]\tvalid_0's rmse: 0.883507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Did not meet early stopping. Best iteration is:                                                                         \n",
      "[151]\tvalid_0's rmse: 0.884783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000573 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[22]\tvalid_0's rmse: 0.918049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000228 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[49]\tvalid_0's rmse: 0.885592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[45]\tvalid_0's rmse: 0.896901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[46]\tvalid_0's rmse: 0.888344\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[17]\tvalid_0's rmse: 0.953592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf                                              \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[76]\tvalid_0's rmse: 0.884767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[54]\tvalid_0's rmse: 0.885125\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000208 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[22]\tvalid_0's rmse: 0.906356\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[113]\tvalid_0's rmse: 0.885881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000603 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[62]\tvalid_0's rmse: 0.889346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[180]\tvalid_0's rmse: 0.884092\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.                 \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[99]\tvalid_0's rmse: 0.883988\n",
      "100%|| 50/50 [01:17<00:00,  1.55s/trial, best loss: 0.8812156810825201]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05109299271953994,\n",
       " 'max_depth': 81.0,\n",
       " 'min_child_weight': 1.6426947252273845,\n",
       " 'n_estimators': 487.0,\n",
       " 'reg_alpha': 0.09516892233034042,\n",
       " 'reg_lambda': 0.07910213506368764,\n",
       " 'subsample': 0.8140563290026308}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 2000, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'subsample':        hp.uniform('subsample', 0.6, 1),\n",
    "    'objective': 'regression',\n",
    "    # \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 20, 40, 2)),\n",
    "    \"first_metric_only\": True,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# search_space = {\n",
    "#         \"n_estimators\": 100,\n",
    "#         \"learning_rate\": hp.loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "#         \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 20, 3000, 20)),\n",
    "#         \"max_depth\": scope.int(hp.quniform(\"max_depth\", 3, 12, 1)),\n",
    "#         \"min_data_in_leaf\": scope.int(hp.quniform(\"min_data_in_leaf\", 200, 10000, 100)),\n",
    "#         \"max_bin\": scope.int(hp.quniform(\"max_bin\", 200, 300, 1)),\n",
    "#         \"lambda_l1\": scope.int(hp.quniform(\"lambda_l1\", 0, 100, 5)),\n",
    "#         \"lambda_l2\": scope.int(hp.quniform(\"lambda_l2\", 0, 100, 5)),\n",
    "#         \"min_gain_to_split\": hp.loguniform(\"min_gain_to_split\", 0, 15),\n",
    "#         # \"bagging_fraction\": hp.loguniform(\n",
    "#         #     \"bagging_fraction\", 0.2, 0.95, 0.1\n",
    "#         # ),\n",
    "#         # # \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "#         # \"feature_fraction\": hp.loguniform(\n",
    "#         #     \"feature_fraction\", 0.2, 0.95, 0.1\n",
    "#         # ),\n",
    "#         'seed': 42\n",
    "#         }\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    # space=lgb_reg_params,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    ")\n",
    "\n",
    "best_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df6f96ed-b592-4912-b2a8-2ab15bd43ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters with the best score is  {'learning_rate': 0.05109299271953994, 'max_depth': 81.0, 'min_child_weight': 1.6426947252273845, 'n_estimators': 487.0, 'reg_alpha': 0.09516892233034042, 'reg_lambda': 0.07910213506368764, 'subsample': 0.8140563290026308}\n"
     ]
    }
   ],
   "source": [
    "print(\"The hyperparameters with the best score is \", best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "520e6954-4428-41c1-9948-a77a14116ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(params):\n",
    "\n",
    "    mlflow.set_experiment(\"log-best-model\")\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "         \n",
    "        mlflow.set_tag(\"developer\", \"hema\")\n",
    "\n",
    "        mlflow.log_param(\"train-data-path\", input_file)\n",
    "        mlflow.log_param(\"test-data-path\",input_file)\n",
    "        mlflow.log_param(\"model\", \"lgbm\")\n",
    "    \n",
    "        lgbm = lgb.LGBMRegressor(n_jobs=-1,**params, metric='rmse')\n",
    "\n",
    "        lgbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "                 callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50)]\n",
    "                )\n",
    "        y_pred_lgbm_reg = lgbm.predict(X_test)\n",
    "        lgbm_rmse = mean_squared_error(y_test, y_pred_lgbm_reg, squared=False)\n",
    "        mlflow.log_metric(\"rmse_lgbm\", lgbm_rmse)\n",
    "        mlflow.sklearn.log_model(lgbm, \"lgbm_reg\")\n",
    "        with open('models/preprocessor.b', 'wb') as f_out:\n",
    "            pickle.dump((dv, lgbm), f_out)\n",
    "        mlflow.log_artifact(local_path=\"models/preprocessor.b\", artifact_path=\"models_mlflow\")\n",
    "    \n",
    "        return {'loss': lgbm_rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "740fc876-ca7f-47a4-a02f-e6e40a2f1400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/18 19:01:57 INFO mlflow.tracking.fluent: Experiment with name 'log-best-model' does not exist. Creating a new experiment.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002628 seconds.                 \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 933                                                                                        \n",
      "[LightGBM] [Info] Number of data points in the train set: 10278, number of used features: 18                            \n",
      "[LightGBM] [Info] Start training from score 11.487968                                                                   \n",
      "Training until validation scores don't improve for 50 rounds                                                            \n",
      "Early stopping, best iteration is:                                                                                      \n",
      "[179]\tvalid_0's rmse: 0.881216\n",
      "  0%|                                                                             | 0/1 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/18 19:02:14 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:18<00:00, 18.01s/trial, best loss: 0.8812156810825201]\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'learning_rate': 0.05109299271953994,\n",
    "     'max_depth': 81,\n",
    "     'min_child_weight': 1.6426947252273845,\n",
    "     'n_estimators': 487,\n",
    "     'reg_alpha': 0.09516892233034042,\n",
    "     'reg_lambda': 0.07910213506368764,\n",
    "     'subsample': 0.8140563290026308,\n",
    "     'objective': 'regression',\n",
    "      \"seed\": 42\n",
    "}\n",
    "\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1,\n",
    "    trials=Trials()\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
